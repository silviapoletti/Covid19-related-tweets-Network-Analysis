{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summary_SeptOct2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#notebook to download the csv of edges and nodes of a given network\n",
        "import os\n",
        "import requests \n",
        "import time\n",
        "import string\n",
        "import networkx as nx\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.corpus import wordnet as wn #importing it\n",
        "from nltk.stem.wordnet import WordNetLemmatizer #importing wordnet lemmatizer\n",
        "from nltk import pos_tag #part-of-speech-tagger\n",
        "from collections import defaultdict #defaultdict returns default value for non-existant keys you try to  access based on the function you passed in the constructor\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcCylkZqDPi",
        "outputId": "2fe79134-9577-4d31-853c-db5657afa87e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(df):       #extract the text from the tweets and RT\n",
        "                            #works ONLY on .csv file\n",
        "  list_strings = []\n",
        "  for index in range(len(df)):\n",
        "    if index % 1000 == 0:\n",
        "      print(str(index)+' / '+str(len(df)))\n",
        "    text = df.loc[index]['text']                          #if it is nor trucated nor a RT  i take \"text\"\n",
        "    string = -1\n",
        "    if (df.loc[index,\"truncated\"] == True):                 #if it is trucated I take \"extended_tweet\"\n",
        "        string = df.loc[index,\"extended_tweet\"]\n",
        "    if type(df.loc[index,\"retweeted_status\"]) != float:     #if it is a RT I take retweeted_status\n",
        "        string = df.loc[index,\"retweeted_status\"]\n",
        "    if type(string) == str :\n",
        "        if(re.search('full_text\\':(.+?)https',string) != None):     #if I find \"full_text\"\n",
        "          s = re.search('full_text\\':(.+?)https',string).group(1)\n",
        "        if(re.search('text\\':(.+?)https',string)!= None):\n",
        "          s = re.search('text\\':(.+?)https',string).group(1)\n",
        "        else: \n",
        "          continue\n",
        "        list_strings.append(s)\n",
        "        #print(s)         \n",
        "    else:\n",
        "      list_strings.append(text)\n",
        "      #print(text)\n",
        "      \n",
        "\n",
        "  return list_strings"
      ],
      "metadata": {
        "id": "CGa_FVVGqDSJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning, lemmatising and pos tagging tweets\n",
        "\n",
        "nltk.download('words')\n",
        "WORDS = set(nltk.corpus.words.words()) #the last two lines serve to download the corpus of standard English language words\n",
        "nltk.download('stopwords') #downloading stopwords\n",
        "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\")) #taking the stop words from English language\n",
        "nltk.download('wordnet') #downloading wordnet\n",
        "nltk.download('averaged_perceptron_tagger') #downloading tagger\n",
        "tag_map = defaultdict(lambda : wn.NOUN) #here we define that wn.NOUN is the default value for the dict\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "\n",
        "def lemma_pos_cleaner(tweet):\n",
        "\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) # remove mentions\n",
        "    tweet = re.sub(\"#[A-Za-z0-9]+\", \"\",tweet) # remove hashtags\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) # remove http links\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = str.lower(tweet) #to lowercase \n",
        "    tweet = re.sub(\"'\",\" \",tweet) # remove aphostrophe\n",
        "\n",
        "    #basically we use pos_tag function on tokens that we get by applying wordpunct tokenization\n",
        "    #to tweet (it separates all the words and symbols)\n",
        "    #then we pass the token along with it's wordnet pos value that we get from the tag_map dictionary (noun, adjective, verb or adverb) to the lemma function (the WordNetLemmatizer())\n",
        "    lemma_function = WordNetLemmatizer()\n",
        "    tweet = \" \".join(lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in nltk.pos_tag(nltk.wordpunct_tokenize(tweet))) #lemmatize\n",
        "  \n",
        "\n",
        "    # francesco: I removed also all 2 letters words and added specific words, words that appears frequently but are discarded because they are not in the english language\n",
        "    SPECIFIC_WORDS = ['virus', 'coronavirus', 'covid19', 'covid', 'trump', 'hubei', 'beijing', 'xinjiang', 'jinping', 'korea', 'xinhua', 'india', 'taiwan','johnson','singapore', 'africa', 'japanese', 'france', 'asian', 'australia', 'french', 'asia', 'leishenshan', 'british', 'qingdao', 'fauci', 'america',  'california', 'sichuan', 'malaysia', 'huawei','thailand', 'shandong', 'italy', 'philippines', 'germany', 'facebook', 'african', 'shenzhen', 'tokyo', 'russian','uygur', '5g', 'pompeo', 'vietnam', 'australian', 'cambodia', 'zhejiang', 'yunnan', 'guangdong', 'korean', 'iran', 'washington']\n",
        "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if (w in WORDS or w in SPECIFIC_WORDS) and len(w)>2 and w not in STOP_WORDS ) #remove stop words\n",
        "   \n",
        "    return tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0LDoYVqDUh",
        "outputId": "aa092e05-4ffc-4bb9-c476-c38e6bce8467"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency_dictionary(df):\n",
        "  unique_words = {}\n",
        "\n",
        "  for row in df:\n",
        "    for word in row.split():\n",
        "      #if the word is encountered for the first time add to dict as key and set its value to 0\n",
        "      unique_words.setdefault(word,0)\n",
        "      #increase the value (i.e the count) of the word by 1 every time it is encountered\n",
        "      unique_words[word] += 1\n",
        "\n",
        "  return unique_words"
      ],
      "metadata": {
        "id": "MAfOr8vR4P88"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "def clean_words(cleaned_text, unuseful_words):\n",
        "  re_cleaned_text = cleaned_text.copy()\n",
        "  for txt in range(len(re_cleaned_text)):\n",
        "    if txt % 2000 == 0:\n",
        "      print(txt, '/',len(re_cleaned_text))\n",
        "    w = re_cleaned_text[txt].split()\n",
        "    for word in unuseful_words:\n",
        "      while word in w:\n",
        "        w.remove(word)\n",
        "    re_cleaned_text[txt] = ' '.join(w)\n",
        "  return re_cleaned_text"
      ],
      "metadata": {
        "id": "_qrTtTxDgYKz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period = '_SeptOct2020'  # '', '_JanFeb2020', '_MarchApril2021', '_SeptOct2020'"
      ],
      "metadata": {
        "id": "o-GUlzAVOwk_"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "China = pd.read_csv('/content/China'+period+'.csv')\n",
        "USA = pd.read_csv('/content/USA'+period+'.csv')\n",
        "China_USA = pd.read_csv('/content/China&USA'+period+'.csv')"
      ],
      "metadata": {
        "id": "suPdLaUx1Ct8"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of tweets:\n",
        "print('China: ', len(China))\n",
        "print('USA: ', len(USA))\n",
        "print('China&USA: ', len(China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeO9nxO6Br3x",
        "outputId": "302f0bcf-999c-4e36-c260-3014418f999f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  1291\n",
            "USA:  7436\n",
            "China&USA:  8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_China = extract_text(China)\n",
        "text_USA = extract_text(USA)\n",
        "text_China_USA = extract_text(China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WI3Rz9T1Cxo",
        "outputId": "1e838ee1-ba4e-4cd1-fd9f-32849fac825b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 1291\n",
            "1000 / 1291\n",
            "0 / 7436\n",
            "1000 / 7436\n",
            "2000 / 7436\n",
            "3000 / 7436\n",
            "4000 / 7436\n",
            "5000 / 7436\n",
            "6000 / 7436\n",
            "7000 / 7436\n",
            "0 / 8727\n",
            "1000 / 8727\n",
            "2000 / 8727\n",
            "3000 / 8727\n",
            "4000 / 8727\n",
            "5000 / 8727\n",
            "6000 / 8727\n",
            "7000 / 8727\n",
            "8000 / 8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text_China = [lemma_pos_cleaner(txt) for txt in text_China]\n",
        "cleaned_text_USA = [lemma_pos_cleaner(txt) for txt in text_USA]\n",
        "cleaned_text_China_USA = [lemma_pos_cleaner(txt) for txt in text_China_USA]\n",
        "\n",
        "print('China:')\n",
        "print(cleaned_text_China[0:10])\n",
        "print()\n",
        "print('USA:')\n",
        "print(cleaned_text_USA[0:10])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(cleaned_text_China_USA[0:10])"
      ],
      "metadata": {
        "id": "6q4JI_jV1C2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e23c8e-2475-43b0-926a-fb0e528e32ac"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "['daily case coronavirus infection high since mid summer see number expert express concern rapid acceleration covid case', 'presidential election approach voter see country deeply polarize key issue', 'government impose tough new restriction northern city late', 'covid case surpass million week pandemic take toll labor market economy', 'number coronavirus confirm case surpass one million week many health worker', 'number death africa coronavirus surpass mark world health say', 'become first country western report one million confirm covid infection continent grapple resurgence case', 'become first country western reach million confirm covid case accord health ministry', 'president urge vigilance possible second wave covid', 'germany federal minister health test positive coronavirus local medium report']\n",
            "\n",
            "USA:\n",
            "['global covid case surpass million coronavirus news follow coverage', 'since start covid pandemic lot misinformation look common coronavirus', 'myth shoe clothes spread coronavirus', 'myth antibiotic kill coronavirus', 'since start covid pandemic lot misinformation look common coronavirus misconception stop spread', 'india may see covid case month rule relax accord scientific panel', 'india may see covid case month rule relax panel', 'covid news follow coverage', 'covid news follow coverage', 'report strong international coronavirus vaccine could speed world economic recovery add trillion global income']\n",
            "\n",
            "China&USA:\n",
            "['daily case coronavirus infection high since mid summer see number expert express concern rapid acceleration covid case', 'presidential election approach voter see country deeply polarize key issue', 'government impose tough new restriction northern city late', 'covid case surpass million week pandemic take toll labor market economy', 'number coronavirus confirm case surpass one million week many health worker', 'number death africa coronavirus surpass mark world health say', 'become first country western report one million confirm covid infection continent grapple resurgence case', 'become first country western reach million confirm covid case accord health ministry', 'president urge vigilance possible second wave covid', 'germany federal minister health test positive coronavirus local medium report']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCiw0q7t4UER",
        "outputId": "d6c91f36-ca64-47a2-e3e3-41eab37032ab"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  2233\n",
            "USA:  4587\n",
            "China&USA:  4967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent words\n",
        "print('China')\n",
        "print([key for key in freq_dict_China.keys() if freq_dict_China[key]>100])\n",
        "print()\n",
        "print('USA')\n",
        "print([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>100])\n",
        "print()\n",
        "print('China&USA')\n",
        "print([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29OU9Cd5Auv",
        "outputId": "bd8580b0-8593-4431-86ac-a012ec772080"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "['covid', 'case', 'coronavirus', 'say', 'new', 'china', 'report', 'test', 'president', 'health', 'pandemic', 'country', 'trump', 'vaccine', 'watch', 'positive']\n",
            "\n",
            "USA\n",
            "['covid', 'coronavirus', 'say', 'trump', 'vaccine', 'new', 'case', 'test', 'president', 'pandemic', 'positive', 'report', 'house', 'people', 'death', 'day', 'health', 'white', 'first', 'state', 'million', 'infection', 'trial', 'week', 'month', 'world', 'one', 'rise', 'country', 'virus', 'take', 'record', 'china', 'get', 'make', 'could', 'may', 'study', 'johnson', 'time', 'hospital', 'restriction', 'year', 'second', 'two', 'global', 'surge', 'see', 'high', 'spread', 'plan', 'government', 'accord', 'mask', 'minister', 'daily', 'hit', 'work', 'outbreak', 'back', 'election', 'city', 'late', 'official', 'amid', 'show', 'help', 'face', 'since', 'campaign', 'risk', 'top', 'use', 'india', 'follow', 'public', 'home', 'die', 'york', 'debate', 'australia', 'due', 'still', 'curb', 'last', 'close', 'need', 'return', 'know', 'presidential', 'data', 'joe', 'set', 'would', 'result', 'aid', 'end', 'relief', 'wave', 'expert', 'chief', 'rule', 'south', 'start', 'number', 'emergency', 'patient', 'three', 'deal', 'drug', 'around', 'treatment', 'tell', 'worker', 'doctor', 'come', 'news', 'call', 'exclusive', 'negative', 'increase', 'long', 'medical', 'big', 'hold', 'lady']\n",
            "\n",
            "China&USA\n",
            "['covid', 'coronavirus', 'say', 'trump', 'case', 'new', 'vaccine', 'test', 'president', 'report', 'pandemic', 'positive', 'house', 'health', 'people', 'death', 'day', 'million', 'china', 'first', 'white', 'country', 'state', 'world', 'infection', 'trial', 'week', 'one', 'month', 'rise', 'virus', 'take', 'record', 'year', 'accord', 'global', 'may', 'get', 'make', 'see', 'could', 'time', 'high', 'second', 'restriction', 'study', 'johnson', 'hospital', 'two', 'surge', 'city', 'spread', 'government', 'minister', 'late', 'daily', 'plan', 'official', 'amid', 'hit', 'since', 'outbreak']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# less frequent words: not performed on data with only covid, coronavirus, vaccine keys"
      ],
      "metadata": {
        "id": "9oHPXYbpINWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less frequent words:\n",
        "thr = 2\n",
        "print('Less frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]<thr]))\n",
        "print('More frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]>=thr]))\n",
        "less_frequent_words_China = [key for key in freq_dict_China.keys() if freq_dict_China[key]<thr]\n",
        "print()\n",
        "print('Less frequent USA: ', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]<thr]))\n",
        "print('More frequent USA:', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>=thr]))\n",
        "less_frequent_words_USA = [key for key in freq_dict_USA.keys() if freq_dict_USA[key]<thr]\n",
        "print()\n",
        "print('Less frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<thr]))\n",
        "print('More frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>=thr]))\n",
        "less_frequent_words_China_USA = [key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<thr]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgiQzaHD5zAb",
        "outputId": "fb9e2fde-5a52-4ce5-a9ad-402ceec94818"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Less frequent China:  1132\n",
            "More frequent China:  1761\n",
            "\n",
            "Less frequent USA:  820\n",
            "More frequent USA: 1920\n",
            "\n",
            "Less frequent China&USA:  1288\n",
            "More frequent China&USA:  2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "def clean_words(cleaned_text, unuseful_words):\n",
        "  re_cleaned_text = cleaned_text.copy()\n",
        "  for txt in range(len(re_cleaned_text)):\n",
        "    if txt % 2000 == 0:\n",
        "      print(txt, '/',len(re_cleaned_text))\n",
        "    w = re_cleaned_text[txt].split()\n",
        "    for word in unuseful_words:\n",
        "      while word in w:\n",
        "        w.remove(word)\n",
        "    re_cleaned_text[txt] = ' '.join(w)\n",
        "  return re_cleaned_text"
      ],
      "metadata": {
        "id": "wGHsUAKwkg4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_mostfreq_text_China = clean_words(cleaned_text_China, less_frequent_words_China)\n",
        "cleaned_mostfreq_text_USA = clean_words(cleaned_text_USA, less_frequent_words_USA)\n",
        "cleaned_mostfreq_text_China_USA = clean_words(cleaned_text_China_USA, less_frequent_words_China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmlqtzHp6lh8",
        "outputId": "337c39ff-9fa1-4262-992c-f64708f0b7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 2438\n",
            "2000 / 2438\n",
            "0 / 3185\n",
            "2000 / 3185\n",
            "0 / 5623\n",
            "2000 / 5623\n",
            "4000 / 5623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostfreq_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostfreq_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostfreq_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KHj5-o57f8y",
        "outputId": "a93b1c2f-f043-4cda-8694-4ed382162367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  497\n",
            "USA:  576\n",
            "China&USA:  941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Network"
      ],
      "metadata": {
        "id": "1davLfA3HNV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxPPnevj890b",
        "outputId": "5d585218-7691-44eb-97d8-b07e9bdd0050"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         covid    542\n",
            "1          case    271\n",
            "2   coronavirus    252\n",
            "3           say    196\n",
            "4           new    194\n",
            "5         china    174\n",
            "6        report    171\n",
            "7          test    150\n",
            "8     president    146\n",
            "9        health    133\n",
            "10     pandemic    123\n",
            "11      country    115\n",
            "12        trump    114\n",
            "13      vaccine    114\n",
            "14        watch    111\n",
            "15     positive    101\n",
            "16        world     92\n",
            "17      million     90\n",
            "18        death     85\n",
            "19       people     81\n",
            "20       accord     80\n",
            "21          day     72\n",
            "22       number     67\n",
            "23         year     64\n",
            "24    infection     63\n",
            "25         city     61\n",
            "26       global     61\n",
            "27        first     59\n",
            "28        house     58\n",
            "29     national     56\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0         covid   4102\n",
            "1   coronavirus   2144\n",
            "2           say   1475\n",
            "3         trump   1264\n",
            "4       vaccine   1121\n",
            "5           new   1083\n",
            "6          case   1012\n",
            "7          test    987\n",
            "8     president    974\n",
            "9      pandemic    575\n",
            "10     positive    565\n",
            "11       report    536\n",
            "12        house    457\n",
            "13       people    397\n",
            "14        death    390\n",
            "15          day    379\n",
            "16       health    379\n",
            "17        white    359\n",
            "18        first    353\n",
            "19        state    350\n",
            "20      million    328\n",
            "21    infection    328\n",
            "22        trial    327\n",
            "23         week    308\n",
            "24        month    307\n",
            "25        world    307\n",
            "26          one    295\n",
            "27         rise    288\n",
            "28      country    287\n",
            "29        virus    284\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         covid   4644\n",
            "1   coronavirus   2396\n",
            "2           say   1671\n",
            "3         trump   1378\n",
            "4          case   1283\n",
            "5           new   1277\n",
            "6       vaccine   1235\n",
            "7          test   1137\n",
            "8     president   1120\n",
            "9        report    707\n",
            "10     pandemic    698\n",
            "11     positive    666\n",
            "12        house    515\n",
            "13       health    512\n",
            "14       people    478\n",
            "15        death    475\n",
            "16          day    451\n",
            "17      million    418\n",
            "18        china    418\n",
            "19        first    412\n",
            "20        white    409\n",
            "21      country    402\n",
            "22        state    401\n",
            "23        world    399\n",
            "24    infection    391\n",
            "25        trial    354\n",
            "26         week    348\n",
            "27          one    343\n",
            "28        month    330\n",
            "29         rise    323\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "zHmEpbLtr46D"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(cleaned_text):\n",
        "  network = {}\n",
        "  #connect the word that appear in the same tweets\n",
        "  for row in cleaned_text:\n",
        "    combined_list = [word for word in str.split(row)]\n",
        "    #for pair in itertools.product(combined_list, combined_list):\n",
        "    #print(combined_list)\n",
        "    for pair in itertools.product(combined_list, combined_list):\n",
        "          #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
        "          if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
        "              network.setdefault(pair,0)\n",
        "              network[pair] += 1 \n",
        "  network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
        "  network_df.columns = [\"weight\"]\n",
        "  network_df.sort_values(by=\"weight\",inplace=True, ascending=False)\n",
        "  return network, network_df"
      ],
      "metadata": {
        "id": "nUAWB6lT1DAd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_text_China_USA)"
      ],
      "metadata": {
        "id": "7vR_r37vAGye"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMWDZua_b-l",
        "outputId": "006f0da1-1f0f-4e24-c080-1c5fa4264e2b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                     weight\n",
            "(new, case)             148\n",
            "(report, case)          145\n",
            "(case, covid)           141\n",
            "(china, covid)          112\n",
            "(test, positive)        108\n",
            "(covid, new)            105\n",
            "(report, new)           104\n",
            "(covid, say)            103\n",
            "(president, trump)       94\n",
            "(covid, pandemic)        86\n",
            "(report, covid)          84\n",
            "(president, covid)       78\n",
            "(case, health)           75\n",
            "(covid, test)            73\n",
            "(covid, trump)           62\n",
            "(case, coronavirus)      62\n",
            "(new, health)            61\n",
            "(say, president)         59\n",
            "(white, house)           59\n",
            "(new, coronavirus)       56\n",
            "(country, covid)         56\n",
            "(trump, test)            55\n",
            "(covid, positive)        55\n",
            "(covid, million)         54\n",
            "(case, number)           54\n",
            "(case, total)            54\n",
            "(case, million)          54\n",
            "(death, case)            51\n",
            "(health, report)         50\n",
            "(confirm, case)          50\n",
            "\n",
            "USA:\n",
            "                          weight\n",
            "(president, trump)          1010\n",
            "(say, covid)                 807\n",
            "(covid, vaccine)             724\n",
            "(trump, covid)               679\n",
            "(test, covid)                677\n",
            "(new, covid)                 651\n",
            "(covid, case)                650\n",
            "(test, positive)             579\n",
            "(say, trump)                 549\n",
            "(president, covid)           495\n",
            "(say, coronavirus)           488\n",
            "(new, case)                  461\n",
            "(trump, coronavirus)         460\n",
            "(president, say)             428\n",
            "(white, house)               412\n",
            "(trump, test)                403\n",
            "(positive, covid)            387\n",
            "(case, coronavirus)          365\n",
            "(president, coronavirus)     359\n",
            "(new, coronavirus)           357\n",
            "(say, test)                  351\n",
            "(report, case)               333\n",
            "(test, coronavirus)          321\n",
            "(report, covid)              316\n",
            "(vaccine, trial)             306\n",
            "(trump, house)               301\n",
            "(trump, positive)            295\n",
            "(report, new)                286\n",
            "(president, test)            284\n",
            "(trump, white)               284\n",
            "\n",
            "China&USA:\n",
            "                          weight\n",
            "(president, trump)          1104\n",
            "(covid, say)                 910\n",
            "(case, covid)                791\n",
            "(covid, vaccine)             767\n",
            "(covid, new)                 756\n",
            "(covid, test)                750\n",
            "(covid, trump)               741\n",
            "(test, positive)             687\n",
            "(new, case)                  609\n",
            "(say, trump)                 590\n",
            "(president, covid)           573\n",
            "(coronavirus, say)           524\n",
            "(say, president)             487\n",
            "(coronavirus, trump)         484\n",
            "(report, case)               478\n",
            "(white, house)               471\n",
            "(trump, test)                458\n",
            "(covid, positive)            442\n",
            "(case, coronavirus)          427\n",
            "(new, coronavirus)           413\n",
            "(report, covid)              400\n",
            "(report, new)                390\n",
            "(coronavirus, president)     389\n",
            "(say, test)                  381\n",
            "(test, coronavirus)          362\n",
            "(vaccine, trial)             330\n",
            "(trump, positive)            328\n",
            "(house, trump)               326\n",
            "(covid, pandemic)            322\n",
            "(president, test)            321\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graph\n"
      ],
      "metadata": {
        "id": "gfvo8x0Ku78D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(network):\n",
        "  G = nx.Graph()\n",
        "  for edge in network:\n",
        "      G.add_edge(edge[0], edge[1], weight=network[edge])\n",
        "  return G"
      ],
      "metadata": {
        "id": "2NGKuSuYAo-K"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "TbpTF19bBKJq"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "id": "W178ljb9rM6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c4cf03-b8a3-4ea2-ef89-0b95f0c6880f"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  2233\n",
            "Edges:  46601\n",
            "Is connected:  False\n",
            "\n",
            "USA:\n",
            "Nodes:  4587\n",
            "Edges:  178578\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  4967\n",
            "Edges:  207161\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PageRank"
      ],
      "metadata": {
        "id": "1LYNr4McLtWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "P6qJVv9vHIr1"
      },
      "outputs": [],
      "source": [
        "# Calculating the pagerank on graph G, teleportation probability here is 0.15 but since the graph is strongly connected we can set it to zero if we want\n",
        "pr_China = nx.algorithms.pagerank(G_China,alpha = 1)\n",
        "pr_China = dict(sorted(pr_China.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_USA = nx.algorithms.pagerank(G_USA,alpha = 1)\n",
        "pr_USA = dict(sorted(pr_USA.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_China_USA = nx.algorithms.pagerank(G_China_USA,alpha = 1)\n",
        "pr_China_USA = dict(sorted(pr_China_USA.items(), key=lambda item: item[1],reverse  = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BcVoAXxqpqLd"
      },
      "outputs": [],
      "source": [
        "def threshold(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] >= threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_reverse(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] < threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ],
      "metadata": {
        "id": "7-UFIOEJL6bY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cUhquN72cI6",
        "outputId": "7578915e-5656-462d-dbe2-d39069fd5e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  518\n",
            "\n",
            "              0         1\n",
            "0         covid  0.036656\n",
            "1          case  0.018083\n",
            "2   coronavirus  0.016590\n",
            "3           say  0.015262\n",
            "4         china  0.014178\n",
            "5           new  0.013570\n",
            "6        report  0.012298\n",
            "7     president  0.010980\n",
            "8          test  0.010234\n",
            "9        health  0.009925\n",
            "10     pandemic  0.008884\n",
            "11      country  0.008753\n",
            "12        trump  0.008528\n",
            "13        world  0.007247\n",
            "14      vaccine  0.007181\n",
            "15     positive  0.007175\n",
            "16      million  0.006152\n",
            "17          day  0.005901\n",
            "18       accord  0.005880\n",
            "19        death  0.005781\n",
            "20       people  0.005621\n",
            "21         year  0.004963\n",
            "22         city  0.004927\n",
            "23    infection  0.004917\n",
            "24       number  0.004810\n",
            "25        first  0.004609\n",
            "26        house  0.004542\n",
            "27       global  0.004182\n",
            "28         hour  0.003947\n",
            "29     national  0.003926\n",
            "\n",
            "USA:  513\n",
            "\n",
            "              0         1\n",
            "0         covid  0.038157\n",
            "1   coronavirus  0.023285\n",
            "2           say  0.018489\n",
            "3         trump  0.017661\n",
            "4     president  0.013844\n",
            "5       vaccine  0.011445\n",
            "6          test  0.011223\n",
            "7           new  0.011130\n",
            "8          case  0.008846\n",
            "9      pandemic  0.007588\n",
            "10     positive  0.006645\n",
            "11        house  0.006619\n",
            "12        white  0.005481\n",
            "13       people  0.005409\n",
            "14       report  0.005061\n",
            "15        first  0.004724\n",
            "16       health  0.004613\n",
            "17          day  0.004370\n",
            "18        state  0.004183\n",
            "19         week  0.004122\n",
            "20          one  0.004115\n",
            "21        month  0.004053\n",
            "22        virus  0.003944\n",
            "23        world  0.003861\n",
            "24        death  0.003615\n",
            "25        trial  0.003564\n",
            "26      country  0.003523\n",
            "27    infection  0.003516\n",
            "28      million  0.003451\n",
            "29         make  0.003131\n",
            "\n",
            "China&USA:  508\n",
            "\n",
            "              0         1\n",
            "0         covid  0.037968\n",
            "1   coronavirus  0.022356\n",
            "2           say  0.018049\n",
            "3         trump  0.016392\n",
            "4     president  0.013451\n",
            "5           new  0.011475\n",
            "6          test  0.011088\n",
            "7       vaccine  0.010860\n",
            "8          case  0.010141\n",
            "9      pandemic  0.007775\n",
            "10     positive  0.006721\n",
            "11        house  0.006332\n",
            "12       report  0.006075\n",
            "13       people  0.005440\n",
            "14       health  0.005360\n",
            "15        white  0.005260\n",
            "16        first  0.004709\n",
            "17          day  0.004586\n",
            "18        world  0.004337\n",
            "19      country  0.004257\n",
            "20        state  0.004083\n",
            "21          one  0.004028\n",
            "22         week  0.003992\n",
            "23        china  0.003953\n",
            "24        death  0.003919\n",
            "25      million  0.003830\n",
            "26    infection  0.003714\n",
            "27        month  0.003694\n",
            "28        virus  0.003675\n",
            "29        trial  0.003303\n"
          ]
        }
      ],
      "source": [
        "thr = 0.0004\n",
        "print('China: ', len(threshold(pr_China,thr)))\n",
        "print()\n",
        "print(threshold(pr_China,thr).iloc[:30])\n",
        "print()\n",
        "print('USA: ', len(threshold(pr_USA,thr)))\n",
        "print()\n",
        "print(threshold(pr_USA,thr).iloc[:30])\n",
        "print()\n",
        "print('China&USA: ', len(threshold(pr_China_USA,thr)))\n",
        "print()\n",
        "print(threshold(pr_China_USA,thr).iloc[:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqlZ2nZ9qKW"
      },
      "source": [
        "# TF-IDF: not performed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVbC8VFA9pgw"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,1))   # ngram range can be changed to obtain measures regarding n grams instead of single words\n",
        "\n",
        "X_China = tfidf.fit_transform(cleaned_text_China).toarray()    # entry (i,j) if Tfidf measure of word_list[j] in document i\n",
        "word_list_China = tfidf.get_feature_names_out()\n",
        "\n",
        "X_USA = tfidf.fit_transform(cleaned_text_USA).toarray()\n",
        "word_list_USA = tfidf.get_feature_names_out()\n",
        "\n",
        "X_China_USA = tfidf.fit_transform(cleaned_text_China_USA).toarray()\n",
        "word_list_China_USA = tfidf.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k8fcvKX-yah"
      },
      "outputs": [],
      "source": [
        "tfidf_df_China = pd.DataFrame(X_China,columns = word_list_China)\n",
        "\n",
        "tfidf_df_USA = pd.DataFrame(X_USA,columns = word_list_USA)\n",
        "\n",
        "tfidf_df_China_USA = pd.DataFrame(X_China_USA,columns = word_list_China_USA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUr9_93WCKsj"
      },
      "outputs": [],
      "source": [
        "tfidf_word_measure_China = np.mean(tfidf_df_China,axis = 0)\n",
        "tfidf_word_measure_China = tfidf_word_measure_China.sort_values(ascending = False)\n",
        "tfidf_word_measure_USA = np.mean(tfidf_df_USA,axis = 0)\n",
        "tfidf_word_measure_USA = tfidf_word_measure_USA.sort_values(ascending = False)\n",
        "tfidf_word_measure_China_USA = np.mean(tfidf_df_China_USA,axis = 0)\n",
        "tfidf_word_measure_China_USA = tfidf_word_measure_China_USA.sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(tfidf_word_measure_China[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(tfidf_word_measure_USA[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(tfidf_word_measure_China_USA[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dknv21f3XimF",
        "outputId": "be7d3fd2-d1cb-41ef-af97-37a9994ef55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "covid          0.076069\n",
            "watch          0.059429\n",
            "coronavirus    0.047427\n",
            "case           0.044577\n",
            "china          0.037314\n",
            "say            0.037011\n",
            "new            0.035957\n",
            "test           0.032966\n",
            "report         0.031964\n",
            "president      0.029373\n",
            "pandemic       0.029153\n",
            "vaccine        0.026741\n",
            "trump          0.026549\n",
            "update         0.026117\n",
            "health         0.025600\n",
            "country        0.024406\n",
            "positive       0.023640\n",
            "million        0.020711\n",
            "world          0.020349\n",
            "people         0.020237\n",
            "death          0.019359\n",
            "accord         0.017701\n",
            "late           0.017458\n",
            "sept           0.016890\n",
            "year           0.016416\n",
            "global         0.016072\n",
            "day            0.015739\n",
            "number         0.015450\n",
            "national       0.014457\n",
            "infection      0.014375\n",
            "dtype: float64\n",
            "\n",
            "USA:\n",
            "covid          0.063696\n",
            "coronavirus    0.043593\n",
            "case           0.032740\n",
            "say            0.031375\n",
            "new            0.030973\n",
            "vaccine        0.029819\n",
            "trump          0.026958\n",
            "test           0.026622\n",
            "president      0.021916\n",
            "report         0.021543\n",
            "positive       0.017711\n",
            "pandemic       0.016017\n",
            "death          0.015852\n",
            "day            0.013833\n",
            "house          0.012634\n",
            "infection      0.012417\n",
            "million        0.012382\n",
            "health         0.012242\n",
            "rise           0.012128\n",
            "state          0.011852\n",
            "trial          0.011631\n",
            "people         0.011513\n",
            "record         0.011287\n",
            "china          0.011244\n",
            "first          0.010940\n",
            "world          0.010269\n",
            "white          0.010210\n",
            "week           0.009885\n",
            "month          0.009750\n",
            "one            0.009536\n",
            "dtype: float64\n",
            "\n",
            "China&USA:\n",
            "covid          0.060835\n",
            "coronavirus    0.041928\n",
            "case           0.033042\n",
            "new            0.030410\n",
            "say            0.029997\n",
            "vaccine        0.027990\n",
            "test           0.025911\n",
            "trump          0.025467\n",
            "report         0.022188\n",
            "president      0.021459\n",
            "positive       0.017466\n",
            "pandemic       0.016267\n",
            "death          0.015868\n",
            "day            0.013524\n",
            "china          0.013455\n",
            "health         0.013341\n",
            "million        0.012933\n",
            "house          0.012178\n",
            "infection      0.012158\n",
            "people         0.011836\n",
            "state          0.011514\n",
            "rise           0.011490\n",
            "watch          0.011118\n",
            "record         0.010997\n",
            "world          0.010822\n",
            "country        0.010764\n",
            "trial          0.010702\n",
            "first          0.010654\n",
            "white          0.009986\n",
            "week           0.009475\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reduced graph"
      ],
      "metadata": {
        "id": "4nkLA8k0LB7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less important words:\n",
        "less_important_words_China = list(threshold_reverse(pr_China,thr)[0])\n",
        "\n",
        "less_important_words_USA = list(threshold_reverse(pr_USA,thr)[0])\n",
        "\n",
        "less_important_words_China_USA = list(threshold_reverse(pr_China_USA,thr)[0])"
      ],
      "metadata": {
        "id": "6ndwCL9oLpDA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_mostimp_text_China = clean_words(cleaned_text_China,less_important_words_China)\n",
        "cleaned_mostimp_text_USA = clean_words(cleaned_text_USA,less_important_words_USA)\n",
        "cleaned_mostimp_text_China_USA = clean_words(cleaned_text_China_USA,less_important_words_China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOA3UEyBunzo",
        "outputId": "9bc55ebe-9fad-4305-f8b9-d7c01b0e4082"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 1286\n",
            "0 / 7431\n",
            "2000 / 7431\n",
            "4000 / 7431\n",
            "6000 / 7431\n",
            "0 / 8717\n",
            "2000 / 8717\n",
            "4000 / 8717\n",
            "6000 / 8717\n",
            "8000 / 8717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostimp_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostimp_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostimp_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd023b6-90cc-4b74-9d1e-0c5929d72f84",
        "id": "X2ObCNtJLpDB"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  518\n",
            "USA:  513\n",
            "China&USA:  508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4dc212-1d32-481f-d8a8-cdee32f4fd5e",
        "id": "DfrViAqzNnb9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         covid    542\n",
            "1          case    271\n",
            "2   coronavirus    252\n",
            "3           say    196\n",
            "4           new    194\n",
            "5         china    174\n",
            "6        report    171\n",
            "7          test    150\n",
            "8     president    146\n",
            "9        health    133\n",
            "10     pandemic    123\n",
            "11      country    115\n",
            "12        trump    114\n",
            "13      vaccine    114\n",
            "14        watch    111\n",
            "15     positive    101\n",
            "16        world     92\n",
            "17      million     90\n",
            "18        death     85\n",
            "19       people     81\n",
            "20       accord     80\n",
            "21          day     72\n",
            "22       number     67\n",
            "23         year     64\n",
            "24    infection     63\n",
            "25         city     61\n",
            "26       global     61\n",
            "27        first     59\n",
            "28        house     58\n",
            "29     national     56\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0         covid   4102\n",
            "1   coronavirus   2144\n",
            "2           say   1475\n",
            "3         trump   1264\n",
            "4       vaccine   1121\n",
            "5           new   1083\n",
            "6          case   1012\n",
            "7          test    987\n",
            "8     president    974\n",
            "9      pandemic    575\n",
            "10     positive    565\n",
            "11       report    536\n",
            "12        house    457\n",
            "13       people    397\n",
            "14        death    390\n",
            "15          day    379\n",
            "16       health    379\n",
            "17        white    359\n",
            "18        first    353\n",
            "19        state    350\n",
            "20      million    328\n",
            "21    infection    328\n",
            "22        trial    327\n",
            "23         week    308\n",
            "24        month    307\n",
            "25        world    307\n",
            "26          one    295\n",
            "27         rise    288\n",
            "28      country    287\n",
            "29        virus    284\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         covid   4644\n",
            "1   coronavirus   2396\n",
            "2           say   1671\n",
            "3         trump   1378\n",
            "4          case   1283\n",
            "5           new   1277\n",
            "6       vaccine   1235\n",
            "7          test   1137\n",
            "8     president   1120\n",
            "9        report    707\n",
            "10     pandemic    698\n",
            "11     positive    666\n",
            "12        house    515\n",
            "13       health    512\n",
            "14       people    478\n",
            "15        death    475\n",
            "16          day    451\n",
            "17        china    418\n",
            "18      million    418\n",
            "19        first    412\n",
            "20        white    409\n",
            "21      country    402\n",
            "22        state    401\n",
            "23        world    399\n",
            "24    infection    391\n",
            "25        trial    354\n",
            "26         week    348\n",
            "27          one    343\n",
            "28        month    330\n",
            "29         rise    323\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "Q52SCkkKNncF"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_mostimp_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_mostimp_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_mostimp_text_China_USA)"
      ],
      "metadata": {
        "id": "bPn3tfv7NncF"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34077c1f-3174-49cd-e6f7-c560e2f01ef2",
        "id": "MVggBElVNncF"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                     weight\n",
            "(new, case)             148\n",
            "(report, case)          145\n",
            "(case, covid)           141\n",
            "(china, covid)          112\n",
            "(test, positive)        108\n",
            "(covid, new)            105\n",
            "(report, new)           104\n",
            "(covid, say)            103\n",
            "(president, trump)       94\n",
            "(covid, pandemic)        86\n",
            "(report, covid)          84\n",
            "(president, covid)       78\n",
            "(case, health)           75\n",
            "(covid, test)            73\n",
            "(case, coronavirus)      62\n",
            "(covid, trump)           62\n",
            "(new, health)            61\n",
            "(white, house)           59\n",
            "(say, president)         59\n",
            "(country, covid)         56\n",
            "(new, coronavirus)       56\n",
            "(covid, positive)        55\n",
            "(trump, test)            55\n",
            "(case, million)          54\n",
            "(case, total)            54\n",
            "(covid, million)         54\n",
            "(case, number)           54\n",
            "(death, case)            51\n",
            "(confirm, case)          50\n",
            "(health, report)         50\n",
            "\n",
            "USA:\n",
            "                          weight\n",
            "(president, trump)          1010\n",
            "(say, covid)                 807\n",
            "(covid, vaccine)             724\n",
            "(trump, covid)               679\n",
            "(test, covid)                677\n",
            "(new, covid)                 651\n",
            "(covid, case)                650\n",
            "(test, positive)             579\n",
            "(say, trump)                 549\n",
            "(president, covid)           495\n",
            "(say, coronavirus)           488\n",
            "(new, case)                  461\n",
            "(trump, coronavirus)         460\n",
            "(president, say)             428\n",
            "(white, house)               412\n",
            "(trump, test)                403\n",
            "(positive, covid)            387\n",
            "(case, coronavirus)          365\n",
            "(president, coronavirus)     359\n",
            "(new, coronavirus)           357\n",
            "(say, test)                  351\n",
            "(report, case)               333\n",
            "(test, coronavirus)          321\n",
            "(report, covid)              316\n",
            "(vaccine, trial)             306\n",
            "(trump, house)               301\n",
            "(trump, positive)            295\n",
            "(report, new)                286\n",
            "(trump, white)               284\n",
            "(president, test)            284\n",
            "\n",
            "China&USA:\n",
            "                          weight\n",
            "(president, trump)          1104\n",
            "(covid, say)                 910\n",
            "(case, covid)                791\n",
            "(covid, vaccine)             767\n",
            "(covid, new)                 756\n",
            "(covid, test)                750\n",
            "(covid, trump)               741\n",
            "(test, positive)             687\n",
            "(new, case)                  609\n",
            "(say, trump)                 590\n",
            "(president, covid)           573\n",
            "(coronavirus, say)           524\n",
            "(say, president)             487\n",
            "(coronavirus, trump)         484\n",
            "(report, case)               478\n",
            "(white, house)               471\n",
            "(trump, test)                458\n",
            "(covid, positive)            442\n",
            "(case, coronavirus)          427\n",
            "(new, coronavirus)           413\n",
            "(report, covid)              400\n",
            "(report, new)                390\n",
            "(coronavirus, president)     389\n",
            "(say, test)                  381\n",
            "(test, coronavirus)          362\n",
            "(vaccine, trial)             330\n",
            "(trump, positive)            328\n",
            "(house, trump)               326\n",
            "(covid, pandemic)            322\n",
            "(president, test)            321\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "zNrH5boVNncF"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4b3ef9-e6e8-427a-cfcb-6f7194756b10",
        "id": "kx5041hFNncF"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  518\n",
            "Edges:  19693\n",
            "Is connected:  False\n",
            "\n",
            "USA:\n",
            "Nodes:  513\n",
            "Edges:  48426\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  508\n",
            "Edges:  52453\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save edge list"
      ],
      "metadata": {
        "id": "p4SvWlzSfzFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = './edgelist_China'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_China, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China_SeptOct2020.csv\n",
        "files.download('edgelist_China'+period+'.csv')\n",
        "\n",
        "filename = './edgelist_USA'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_USA_SeptOct2020.csv\n",
        "files.download('edgelist_USA'+period+'.csv')\n",
        "\n",
        "filename = './edgelist_China_USA'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_China_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China_USA_SeptOct2020.csv\n",
        "files.download('edgelist_China_USA'+period+'.csv')"
      ],
      "metadata": {
        "id": "zgmmRGRCrM9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c1574506-82eb-4142-eff5-cc22bcfe9656"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b3ae4795-4c2f-45a7-a788-ee79dee84685\", \"edgelist_China_SeptOct2020.csv\", 310014)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e88cfdbc-ced2-444c-bd53-b7c3178e40c1\", \"edgelist_USA_SeptOct2020.csv\", 741285)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f6fe7ed6-7d5f-4889-89e7-4e311e010912\", \"edgelist_China_USA_SeptOct2020.csv\", 807762)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create Node List\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nWHLO7AhdwzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes(freq_dict, name):\n",
        "  word_nodes = pd.DataFrame.from_dict(freq_dict,orient=\"index\")\n",
        "  word_nodes.reset_index(inplace=True)\n",
        "  word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
        "  word_nodes.rename(columns={\"index\":\"Id\",0:\"delete\"},inplace=True)\n",
        "  word_nodes = word_nodes.drop(columns=['delete'])\n",
        "  nodelist = pd.DataFrame()\n",
        "  nodelist = nodelist.append(word_nodes, ignore_index=True)\n",
        "\n",
        "  nodelist = nodelist.to_csv(\"nodelist_\"+name+\".csv\",index=False)\n",
        "  files.download(\"nodelist_\"+name+\".csv\")\n",
        "  return nodelist, word_nodes"
      ],
      "metadata": {
        "id": "v2GYb2BQFzET"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodelist_China, word_nodes_China = nodes(freq_dict_China,'China'+period)\n",
        "nodelist_USA, word_nodes_USA = nodes(freq_dict_USA,'USA_'+period)\n",
        "nodelist_China_USA, word_nodes_China_USA = nodes(freq_dict_China_USA,'China_USA'+period)\n",
        "\n",
        "print('China:')\n",
        "print(word_nodes_China.head())\n",
        "print()\n",
        "print('USA:')\n",
        "print(word_nodes_USA.head())\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(word_nodes_China_USA.head())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EmQrEHV0F1QY",
        "outputId": "ad82ba73-afdc-49c7-82d4-8596e6e671c2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_987b4d53-1fd6-474c-9d5a-f1879bd43f39\", \"nodelist_China_SeptOct2020.csv\", 7231)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7a9e0e5a-12b5-41ee-a77f-acb95eb5b573\", \"nodelist_USA__SeptOct2020.csv\", 6913)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b77b15c7-56a8-41c4-9a69-c694ba48dec6\", \"nodelist_China_USA_SeptOct2020.csv\", 6891)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "            Id        Label\n",
            "0        covid        covid\n",
            "1         case         case\n",
            "2  coronavirus  coronavirus\n",
            "3          say          say\n",
            "4          new          new\n",
            "\n",
            "USA:\n",
            "            Id        Label\n",
            "0        covid        covid\n",
            "1  coronavirus  coronavirus\n",
            "2          say          say\n",
            "3        trump        trump\n",
            "4      vaccine      vaccine\n",
            "\n",
            "China&USA:\n",
            "            Id        Label\n",
            "0        covid        covid\n",
            "1  coronavirus  coronavirus\n",
            "2          say          say\n",
            "3        trump        trump\n",
            "4         case         case\n",
            "\n"
          ]
        }
      ]
    }
  ]
}