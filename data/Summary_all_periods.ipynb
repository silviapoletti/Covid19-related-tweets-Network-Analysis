{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summary_all_periods.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#notebook to download the csv of edges and nodes of a given network\n",
        "import os\n",
        "import requests \n",
        "import time\n",
        "import string\n",
        "import networkx as nx\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.corpus import wordnet as wn #importing it\n",
        "from nltk.stem.wordnet import WordNetLemmatizer #importing wordnet lemmatizer\n",
        "from nltk import pos_tag #part-of-speech-tagger\n",
        "from collections import defaultdict #defaultdict returns default value for non-existant keys you try to  access based on the function you passed in the constructor\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcCylkZqDPi",
        "outputId": "2fe79134-9577-4d31-853c-db5657afa87e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(df):       #extract the text from the tweets and RT\n",
        "                            #works ONLY on .csv file\n",
        "  list_strings = []\n",
        "  for index in range(len(df)):\n",
        "    if index % 1000 == 0:\n",
        "      print(str(index)+' / '+str(len(df)))\n",
        "    text = df.loc[index]['text']                          #if it is nor trucated nor a RT  i take \"text\"\n",
        "    string = -1\n",
        "    if (df.loc[index,\"truncated\"] == True):                 #if it is trucated I take \"extended_tweet\"\n",
        "        string = df.loc[index,\"extended_tweet\"]\n",
        "    if type(df.loc[index,\"retweeted_status\"]) != float:     #if it is a RT I take retweeted_status\n",
        "        string = df.loc[index,\"retweeted_status\"]\n",
        "    if type(string) == str :\n",
        "        if(re.search('full_text\\':(.+?)https',string) != None):     #if I find \"full_text\"\n",
        "          s = re.search('full_text\\':(.+?)https',string).group(1)\n",
        "        if(re.search('text\\':(.+?)https',string)!= None):\n",
        "          s = re.search('text\\':(.+?)https',string).group(1)\n",
        "        else: \n",
        "          continue\n",
        "        list_strings.append(s)\n",
        "        #print(s)         \n",
        "    else:\n",
        "      list_strings.append(text)\n",
        "      #print(text)\n",
        "      \n",
        "\n",
        "  return list_strings"
      ],
      "metadata": {
        "id": "CGa_FVVGqDSJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning, lemmatising and pos tagging tweets\n",
        "\n",
        "nltk.download('words')\n",
        "WORDS = set(nltk.corpus.words.words()) #the last two lines serve to download the corpus of standard English language words\n",
        "nltk.download('stopwords') #downloading stopwords\n",
        "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\")) #taking the stop words from English language\n",
        "nltk.download('wordnet') #downloading wordnet\n",
        "nltk.download('averaged_perceptron_tagger') #downloading tagger\n",
        "tag_map = defaultdict(lambda : wn.NOUN) #here we define that wn.NOUN is the default value for the dict\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "\n",
        "def lemma_pos_cleaner(tweet):\n",
        "\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) # remove mentions\n",
        "    tweet = re.sub(\"#[A-Za-z0-9]+\", \"\",tweet) # remove hashtags\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) # remove http links\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = str.lower(tweet) #to lowercase \n",
        "    tweet = re.sub(\"'\",\" \",tweet) # remove aphostrophe\n",
        "\n",
        "    #basically we use pos_tag function on tokens that we get by applying wordpunct tokenization\n",
        "    #to tweet (it separates all the words and symbols)\n",
        "    #then we pass the token along with it's wordnet pos value that we get from the tag_map dictionary (noun, adjective, verb or adverb) to the lemma function (the WordNetLemmatizer())\n",
        "    lemma_function = WordNetLemmatizer()\n",
        "    tweet = \" \".join(lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in nltk.pos_tag(nltk.wordpunct_tokenize(tweet))) #lemmatize\n",
        "  \n",
        "\n",
        "    # francesco: I removed also all 2 letters words and added specific words, words that appears frequently but are discarded because they are not in the english language\n",
        "    SPECIFIC_WORDS = ['virus', 'coronavirus', 'covid19', 'covid', 'trump', 'hubei', 'beijing', 'xinjiang', 'jinping', 'korea', 'xinhua', 'india', 'taiwan','johnson','singapore', 'africa', 'japanese', 'france', 'asian', 'australia', 'french', 'asia', 'leishenshan', 'british', 'qingdao', 'fauci', 'america',  'california', 'sichuan', 'malaysia', 'huawei','thailand', 'shandong', 'italy', 'philippines', 'germany', 'facebook', 'african', 'shenzhen', 'tokyo', 'russian','uygur', '5g', 'pompeo', 'vietnam', 'australian', 'cambodia', 'zhejiang', 'yunnan', 'guangdong', 'korean', 'iran', 'washington']\n",
        "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if (w in WORDS or w in SPECIFIC_WORDS) and len(w)>2 and w not in STOP_WORDS ) #remove stop words\n",
        "   \n",
        "    return tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0LDoYVqDUh",
        "outputId": "aa092e05-4ffc-4bb9-c476-c38e6bce8467"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency_dictionary(df):\n",
        "  unique_words = {}\n",
        "\n",
        "  for row in df:\n",
        "    for word in row.split():\n",
        "      #if the word is encountered for the first time add to dict as key and set its value to 0\n",
        "      unique_words.setdefault(word,0)\n",
        "      #increase the value (i.e the count) of the word by 1 every time it is encountered\n",
        "      unique_words[word] += 1\n",
        "\n",
        "  return unique_words"
      ],
      "metadata": {
        "id": "MAfOr8vR4P88"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "def clean_words(cleaned_text, unuseful_words):\n",
        "  re_cleaned_text = cleaned_text.copy()\n",
        "  for txt in range(len(re_cleaned_text)):\n",
        "    if txt % 2000 == 0:\n",
        "      print(txt, '/',len(re_cleaned_text))\n",
        "    w = re_cleaned_text[txt].split()\n",
        "    for word in unuseful_words:\n",
        "      while word in w:\n",
        "        w.remove(word)\n",
        "    re_cleaned_text[txt] = ' '.join(w)\n",
        "  return re_cleaned_text"
      ],
      "metadata": {
        "id": "_qrTtTxDgYKz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period = ''  # '', '_JanFeb2020', '_MarchApril2021', '_SeptOct2020'"
      ],
      "metadata": {
        "id": "o-GUlzAVOwk_"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "China = pd.read_csv('/content/China'+period+'.csv')\n",
        "USA = pd.read_csv('/content/USA'+period+'.csv')\n",
        "China_USA = pd.read_csv('/content/China&USA'+period+'.csv')"
      ],
      "metadata": {
        "id": "suPdLaUx1Ct8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3525e288-c716-4cae-ff5a-ed0e859b9cde"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (34,35,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of tweets:\n",
        "print('China: ', len(China))\n",
        "print('USA: ', len(USA))\n",
        "print('China&USA: ', len(China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeO9nxO6Br3x",
        "outputId": "b06f3c60-db30-48f8-ce5b-eadc02378f17"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  5080\n",
            "USA:  14553\n",
            "China&USA:  19633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_China = extract_text(China)\n",
        "text_USA = extract_text(USA)\n",
        "text_China_USA = extract_text(China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WI3Rz9T1Cxo",
        "outputId": "87d8e296-9080-4332-f922-82d410cf27f7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 5080\n",
            "1000 / 5080\n",
            "2000 / 5080\n",
            "3000 / 5080\n",
            "4000 / 5080\n",
            "5000 / 5080\n",
            "0 / 14553\n",
            "1000 / 14553\n",
            "2000 / 14553\n",
            "3000 / 14553\n",
            "4000 / 14553\n",
            "5000 / 14553\n",
            "6000 / 14553\n",
            "7000 / 14553\n",
            "8000 / 14553\n",
            "9000 / 14553\n",
            "10000 / 14553\n",
            "11000 / 14553\n",
            "12000 / 14553\n",
            "13000 / 14553\n",
            "14000 / 14553\n",
            "0 / 19633\n",
            "1000 / 19633\n",
            "2000 / 19633\n",
            "3000 / 19633\n",
            "4000 / 19633\n",
            "5000 / 19633\n",
            "6000 / 19633\n",
            "7000 / 19633\n",
            "8000 / 19633\n",
            "9000 / 19633\n",
            "10000 / 19633\n",
            "11000 / 19633\n",
            "12000 / 19633\n",
            "13000 / 19633\n",
            "14000 / 19633\n",
            "15000 / 19633\n",
            "16000 / 19633\n",
            "17000 / 19633\n",
            "18000 / 19633\n",
            "19000 / 19633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text_China = [lemma_pos_cleaner(txt) for txt in text_China]\n",
        "cleaned_text_USA = [lemma_pos_cleaner(txt) for txt in text_USA]\n",
        "cleaned_text_China_USA = [lemma_pos_cleaner(txt) for txt in text_China_USA]\n",
        "\n",
        "print('China:')\n",
        "print(cleaned_text_China[0:10])\n",
        "print()\n",
        "print('USA:')\n",
        "print(cleaned_text_USA[0:10])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(cleaned_text_China_USA[0:10])"
      ],
      "metadata": {
        "id": "6q4JI_jV1C2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d39fad2-2d9d-4bbe-a38c-7d831ec3840f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "['talk university challenge china face deal misconception people medium watch', 'traditional medicine use battle covid answer may surprise', 'italy report first death year old man northern new case report', 'evacuee diamond princess cruise ship land hong hong infect', 'fear stop one couple get marry wedding guest include couple wore surgical mask ceremony', 'group molecular biologist might invent portable device detect infect', 'china world make great stride track infectious disease take unexpected turn make hard track', 'member expert advisory committee say important use technology fight', 'world health organization announce lead team international expert currently china', 'outside china confirm case novel covid half cruise ship dock japan rest scatter among country mostly asia']\n",
            "\n",
            "USA:\n",
            "['coronavirus bring anti sentiment south korea', 'coronavirus issue could come bad time start line muller boston university', 'claim two life iran', 'happen catch new', 'vaccine available', 'first case confirm', 'case discover north italy hundred test', 'shameful attack bus carry evacuee china coronavirus outbreak', 'south korea confirm coronavirus case rise read late', 'world grip epidemic dangerous coronavirus racism']\n",
            "\n",
            "China&USA:\n",
            "['talk university challenge china face deal misconception people medium watch', 'traditional medicine use battle covid answer may surprise', 'italy report first death year old man northern new case report', 'evacuee diamond princess cruise ship land hong hong infect', 'fear stop one couple get marry wedding guest include couple wore surgical mask ceremony', 'group molecular biologist might invent portable device detect infect', 'china world make great stride track infectious disease take unexpected turn make hard track', 'member expert advisory committee say important use technology fight', 'world health organization announce lead team international expert currently china', 'outside china confirm case novel covid half cruise ship dock japan rest scatter among country mostly asia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCiw0q7t4UER",
        "outputId": "08d1050f-5850-4e23-f00e-2bff9c06a180"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  4169\n",
            "USA:  6005\n",
            "China&USA:  6916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent words\n",
        "print('China')\n",
        "print([key for key in freq_dict_China.keys() if freq_dict_China[key]>200])\n",
        "print()\n",
        "print('USA')\n",
        "print([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>400])\n",
        "print()\n",
        "print('China&USA')\n",
        "print([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29OU9Cd5Auv",
        "outputId": "3fd05dd8-2f2b-4a9d-a854-d68b842412b4"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "['china', 'covid', 'case', 'vaccine', 'coronavirus', 'novel', 'new', 'say', 'report', 'outbreak', 'hospital', 'health', 'people', 'country', 'patient', 'fight', 'confirm', 'first', 'death', 'president', 'million', 'day', 'world', 'test', 'pandemic', 'city', 'year', 'infection', 'amid', 'one', 'epidemic', 'medical', 'control', 'live', 'number', 'receive']\n",
            "\n",
            "USA\n",
            "['covid', 'coronavirus', 'vaccine', 'say', 'case', 'new', 'china', 'trump', 'test', 'president', 'report', 'death', 'people', 'health', 'outbreak', 'pandemic', 'first', 'state', 'positive', 'country', 'million', 'day', 'world', 'spread', 'infection', 'rise', 'virus', 'house', 'johnson', 'get', 'week', 'trial', 'year', 'month', 'one', 'use', 'global', 'late', 'white', 'take', 'two', 'could', 'official', 'record', 'may']\n",
            "\n",
            "China&USA\n",
            "['covid', 'coronavirus', 'vaccine', 'say', 'china', 'case', 'new', 'test', 'report', 'trump', 'president', 'health', 'outbreak', 'people', 'death', 'first', 'country', 'pandemic', 'novel', 'million', 'day', 'world', 'hospital', 'state', 'positive', 'infection', 'spread', 'virus', 'year', 'one', 'patient', 'get', 'confirm', 'official', 'rise', 'take', 'late', 'week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# less frequent words: not performed on data with only covid, coronavirus, vaccine keys"
      ],
      "metadata": {
        "id": "9oHPXYbpINWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less frequent words:\n",
        "thr = 2\n",
        "print('Less frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]<thr]))\n",
        "print('More frequent China: ', len([key for key in freq_dict_China.keys() if freq_dict_China[key]>=thr]))\n",
        "less_frequent_words_China = [key for key in freq_dict_China.keys() if freq_dict_China[key]<thr]\n",
        "print()\n",
        "print('Less frequent USA: ', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]<thr]))\n",
        "print('More frequent USA:', len([key for key in freq_dict_USA.keys() if freq_dict_USA[key]>=thr]))\n",
        "less_frequent_words_USA = [key for key in freq_dict_USA.keys() if freq_dict_USA[key]<thr]\n",
        "print()\n",
        "print('Less frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<thr]))\n",
        "print('More frequent China&USA: ', len([key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]>=thr]))\n",
        "less_frequent_words_China_USA = [key for key in freq_dict_China_USA.keys() if freq_dict_China_USA[key]<thr]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgiQzaHD5zAb",
        "outputId": "fb9e2fde-5a52-4ce5-a9ad-402ceec94818"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Less frequent China:  1132\n",
            "More frequent China:  1761\n",
            "\n",
            "Less frequent USA:  820\n",
            "More frequent USA: 1920\n",
            "\n",
            "Less frequent China&USA:  1288\n",
            "More frequent China&USA:  2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# discard less frequent words\n",
        "def clean_words(cleaned_text, unuseful_words):\n",
        "  re_cleaned_text = cleaned_text.copy()\n",
        "  for txt in range(len(re_cleaned_text)):\n",
        "    if txt % 2000 == 0:\n",
        "      print(txt, '/',len(re_cleaned_text))\n",
        "    w = re_cleaned_text[txt].split()\n",
        "    for word in unuseful_words:\n",
        "      while word in w:\n",
        "        w.remove(word)\n",
        "    re_cleaned_text[txt] = ' '.join(w)\n",
        "  return re_cleaned_text"
      ],
      "metadata": {
        "id": "wGHsUAKwkg4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_mostfreq_text_China = clean_words(cleaned_text_China, less_frequent_words_China)\n",
        "cleaned_mostfreq_text_USA = clean_words(cleaned_text_USA, less_frequent_words_USA)\n",
        "cleaned_mostfreq_text_China_USA = clean_words(cleaned_text_China_USA, less_frequent_words_China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmlqtzHp6lh8",
        "outputId": "337c39ff-9fa1-4262-992c-f64708f0b7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 2438\n",
            "2000 / 2438\n",
            "0 / 3185\n",
            "2000 / 3185\n",
            "0 / 5623\n",
            "2000 / 5623\n",
            "4000 / 5623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostfreq_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostfreq_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostfreq_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KHj5-o57f8y",
        "outputId": "a93b1c2f-f043-4cda-8694-4ed382162367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  497\n",
            "USA:  576\n",
            "China&USA:  941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Network"
      ],
      "metadata": {
        "id": "1davLfA3HNV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxPPnevj890b",
        "outputId": "6bdbe1f1-0f97-49f1-9b37-85d2343e4811"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         china   1613\n",
            "1         covid   1593\n",
            "2          case    933\n",
            "3       vaccine    906\n",
            "4   coronavirus    852\n",
            "5         novel    847\n",
            "6           new    670\n",
            "7           say    632\n",
            "8        report    502\n",
            "9      outbreak    495\n",
            "10     hospital    474\n",
            "11       health    448\n",
            "12       people    419\n",
            "13      country    384\n",
            "14      patient    366\n",
            "15        fight    357\n",
            "16      confirm    336\n",
            "17        first    323\n",
            "18        death    298\n",
            "19    president    286\n",
            "20      million    275\n",
            "21          day    267\n",
            "22        world    257\n",
            "23         test    248\n",
            "24     pandemic    241\n",
            "25         city    222\n",
            "26         year    219\n",
            "27         amid    216\n",
            "28    infection    216\n",
            "29          one    215\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0         covid   7147\n",
            "1   coronavirus   5048\n",
            "2       vaccine   3282\n",
            "3           say   2741\n",
            "4          case   1943\n",
            "5           new   1889\n",
            "6         china   1694\n",
            "7         trump   1319\n",
            "8          test   1254\n",
            "9     president   1150\n",
            "10       report    973\n",
            "11        death    916\n",
            "12       people    913\n",
            "13       health    901\n",
            "14     outbreak    841\n",
            "15     pandemic    801\n",
            "16        first    780\n",
            "17        state    700\n",
            "18     positive    678\n",
            "19      country    675\n",
            "20      million    653\n",
            "21          day    649\n",
            "22        world    637\n",
            "23       spread    635\n",
            "24    infection    549\n",
            "25         rise    547\n",
            "26        virus    543\n",
            "27        house    532\n",
            "28      johnson    524\n",
            "29          get    521\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         covid   8740\n",
            "1   coronavirus   5900\n",
            "2       vaccine   4188\n",
            "3           say   3373\n",
            "4         china   3307\n",
            "5          case   2876\n",
            "6           new   2559\n",
            "7          test   1502\n",
            "8        report   1475\n",
            "9         trump   1449\n",
            "10    president   1436\n",
            "11       health   1349\n",
            "12     outbreak   1336\n",
            "13       people   1332\n",
            "14        death   1214\n",
            "15        first   1103\n",
            "16      country   1059\n",
            "17     pandemic   1042\n",
            "18        novel    979\n",
            "19      million    928\n",
            "20          day    916\n",
            "21        world    894\n",
            "22     hospital    855\n",
            "23        state    844\n",
            "24     positive    819\n",
            "25    infection    765\n",
            "26       spread    765\n",
            "27        virus    719\n",
            "28         year    697\n",
            "29          one    679\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "zHmEpbLtr46D"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(cleaned_text):\n",
        "  network = {}\n",
        "  #connect the word that appear in the same tweets\n",
        "  for row in cleaned_text:\n",
        "    combined_list = [word for word in str.split(row)]\n",
        "    #for pair in itertools.product(combined_list, combined_list):\n",
        "    #print(combined_list)\n",
        "    for pair in itertools.product(combined_list, combined_list):\n",
        "          #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
        "          if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
        "              network.setdefault(pair,0)\n",
        "              network[pair] += 1 \n",
        "  network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
        "  network_df.columns = [\"weight\"]\n",
        "  network_df.sort_values(by=\"weight\",inplace=True, ascending=False)\n",
        "  return network, network_df"
      ],
      "metadata": {
        "id": "nUAWB6lT1DAd"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_text_China_USA)"
      ],
      "metadata": {
        "id": "7vR_r37vAGye"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMWDZua_b-l",
        "outputId": "b7dd40fb-2e6f-4855-bfdb-506794d5f973"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                      weight\n",
            "(vaccine, covid)         571\n",
            "(new, case)              501\n",
            "(china, novel)           497\n",
            "(report, case)           434\n",
            "(china, covid)           404\n",
            "(confirm, case)          397\n",
            "(china, coronavirus)     319\n",
            "(case, covid)            306\n",
            "(report, new)            304\n",
            "(china, outbreak)        300\n",
            "(china, vaccine)         293\n",
            "(novel, coronavirus)     291\n",
            "(patient, hospital)      275\n",
            "(china, case)            273\n",
            "(death, case)            257\n",
            "(say, china)             257\n",
            "(china, fight)           254\n",
            "(covid, say)             236\n",
            "(new, covid)             233\n",
            "(novel, outbreak)        226\n",
            "(china, new)             206\n",
            "(report, covid)          204\n",
            "(million, covid)         197\n",
            "(case, coronavirus)      193\n",
            "(covid, pandemic)        189\n",
            "(case, number)           189\n",
            "(covid, country)         186\n",
            "(case, total)            180\n",
            "(vaccine, receive)       175\n",
            "(health, covid)          174\n",
            "\n",
            "USA:\n",
            "                         weight\n",
            "(vaccine, covid)           2180\n",
            "(say, covid)               1456\n",
            "(china, coronavirus)       1221\n",
            "(president, trump)         1031\n",
            "(covid, case)              1025\n",
            "(new, covid)               1023\n",
            "(vaccine, say)              892\n",
            "(say, coronavirus)          872\n",
            "(coronavirus, case)         869\n",
            "(test, covid)               785\n",
            "(new, coronavirus)          732\n",
            "(new, case)                 719\n",
            "(trump, covid)              705\n",
            "(test, positive)            685\n",
            "(coronavirus, outbreak)     648\n",
            "(president, covid)          593\n",
            "(trump, say)                561\n",
            "(report, covid)             534\n",
            "(report, case)              502\n",
            "(trump, coronavirus)        490\n",
            "(say, president)            489\n",
            "(test, coronavirus)         481\n",
            "(coronavirus, death)        478\n",
            "(white, house)              472\n",
            "(spread, coronavirus)       466\n",
            "(covid, death)              431\n",
            "(vaccine, trial)            428\n",
            "(report, new)               424\n",
            "(say, test)                 422\n",
            "(positive, covid)           418\n",
            "\n",
            "China&USA:\n",
            "                         weight\n",
            "(vaccine, covid)           2751\n",
            "(covid, say)               1692\n",
            "(china, coronavirus)       1540\n",
            "(case, covid)              1331\n",
            "(new, covid)               1256\n",
            "(new, case)                1220\n",
            "(president, trump)         1135\n",
            "(case, coronavirus)        1062\n",
            "(vaccine, say)             1054\n",
            "(say, coronavirus)          958\n",
            "(report, case)              936\n",
            "(test, covid)               902\n",
            "(coronavirus, new)          891\n",
            "(test, positive)            824\n",
            "(coronavirus, outbreak)     779\n",
            "(trump, covid)              772\n",
            "(report, covid)             738\n",
            "(report, new)               728\n",
            "(president, covid)          723\n",
            "(china, covid)              670\n",
            "(china, outbreak)           659\n",
            "(confirm, case)             644\n",
            "(china, case)               607\n",
            "(trump, say)                606\n",
            "(health, covid)             578\n",
            "(president, say)            570\n",
            "(covid, pandemic)           568\n",
            "(covid, country)            547\n",
            "(million, covid)            546\n",
            "(first, covid)              542\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graph\n"
      ],
      "metadata": {
        "id": "gfvo8x0Ku78D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(network):\n",
        "  G = nx.Graph()\n",
        "  for edge in network:\n",
        "      G.add_edge(edge[0], edge[1], weight=network[edge])\n",
        "  return G"
      ],
      "metadata": {
        "id": "2NGKuSuYAo-K"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "TbpTF19bBKJq"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "id": "W178ljb9rM6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca35e82-39fb-44c1-c669-d28e2e1276aa"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  4169\n",
            "Edges:  149943\n",
            "Is connected:  True\n",
            "\n",
            "USA:\n",
            "Nodes:  6005\n",
            "Edges:  303835\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  6916\n",
            "Edges:  400517\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PageRank"
      ],
      "metadata": {
        "id": "1LYNr4McLtWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "P6qJVv9vHIr1"
      },
      "outputs": [],
      "source": [
        "# Calculating the pagerank on graph G, teleportation probability here is 0.15 but since the graph is strongly connected we can set it to zero if we want\n",
        "pr_China = nx.algorithms.pagerank(G_China,alpha = 1)\n",
        "pr_China = dict(sorted(pr_China.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_USA = nx.algorithms.pagerank(G_USA,alpha = 1)\n",
        "pr_USA = dict(sorted(pr_USA.items(), key=lambda item: item[1],reverse  = True))\n",
        "\n",
        "pr_China_USA = nx.algorithms.pagerank(G_China_USA,alpha = 1)\n",
        "pr_China_USA = dict(sorted(pr_China_USA.items(), key=lambda item: item[1],reverse  = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BcVoAXxqpqLd"
      },
      "outputs": [],
      "source": [
        "def threshold(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] >= threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_reverse(vector,threshold):\n",
        "\n",
        "  l = [(el,vector[el]) for el in vector if vector[el] < threshold ]\n",
        "\n",
        "  return pd.DataFrame(l)"
      ],
      "metadata": {
        "id": "7-UFIOEJL6bY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cUhquN72cI6",
        "outputId": "578b229e-30d8-4a52-9525-79418c2d984a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  483\n",
            "\n",
            "              0         1\n",
            "0         china  0.028052\n",
            "1         covid  0.025787\n",
            "2          case  0.015578\n",
            "3         novel  0.014592\n",
            "4   coronavirus  0.013834\n",
            "5       vaccine  0.013492\n",
            "6           say  0.012795\n",
            "7           new  0.011168\n",
            "8        report  0.008869\n",
            "9        health  0.008739\n",
            "10     outbreak  0.008518\n",
            "11       people  0.008047\n",
            "12     hospital  0.007875\n",
            "13      country  0.007477\n",
            "14      patient  0.006193\n",
            "15      confirm  0.006015\n",
            "16        fight  0.005979\n",
            "17        first  0.005625\n",
            "18        death  0.005371\n",
            "19          day  0.005207\n",
            "20    president  0.005196\n",
            "21        world  0.005025\n",
            "22      million  0.004810\n",
            "23         city  0.004571\n",
            "24         year  0.004439\n",
            "25         test  0.004405\n",
            "26     pandemic  0.004363\n",
            "27          one  0.004259\n",
            "28       number  0.004079\n",
            "29      medical  0.004050\n",
            "\n",
            "USA:  522\n",
            "\n",
            "              0         1\n",
            "0         covid  0.035922\n",
            "1   coronavirus  0.026965\n",
            "2           say  0.017896\n",
            "3       vaccine  0.017150\n",
            "4           new  0.010415\n",
            "5         trump  0.010092\n",
            "6          case  0.009811\n",
            "7     president  0.008697\n",
            "8         china  0.008538\n",
            "9          test  0.007531\n",
            "10       people  0.006456\n",
            "11       health  0.006174\n",
            "12     pandemic  0.005846\n",
            "13       report  0.005160\n",
            "14     outbreak  0.005046\n",
            "15        first  0.004986\n",
            "16        death  0.004848\n",
            "17        state  0.004593\n",
            "18      country  0.004592\n",
            "19        world  0.004304\n",
            "20          day  0.004284\n",
            "21     positive  0.004233\n",
            "22        house  0.004160\n",
            "23        virus  0.004114\n",
            "24      million  0.003612\n",
            "25         year  0.003556\n",
            "26          one  0.003544\n",
            "27        white  0.003531\n",
            "28       spread  0.003527\n",
            "29          get  0.003504\n",
            "\n",
            "China&USA:  509\n",
            "\n",
            "              0         1\n",
            "0         covid  0.033332\n",
            "1   coronavirus  0.023618\n",
            "2           say  0.016600\n",
            "3       vaccine  0.016215\n",
            "4         china  0.013518\n",
            "5          case  0.011262\n",
            "6           new  0.010596\n",
            "7         trump  0.008170\n",
            "8     president  0.007810\n",
            "9        people  0.006860\n",
            "10       health  0.006823\n",
            "11         test  0.006735\n",
            "12       report  0.006096\n",
            "13     outbreak  0.005935\n",
            "14     pandemic  0.005468\n",
            "15      country  0.005324\n",
            "16        first  0.005146\n",
            "17        death  0.004974\n",
            "18          day  0.004517\n",
            "19        world  0.004489\n",
            "20        novel  0.004472\n",
            "21        state  0.004085\n",
            "22        virus  0.004025\n",
            "23      million  0.003913\n",
            "24     hospital  0.003847\n",
            "25     positive  0.003824\n",
            "26         year  0.003781\n",
            "27          one  0.003724\n",
            "28        house  0.003452\n",
            "29    infection  0.003330\n"
          ]
        }
      ],
      "source": [
        "thr = 0.0004\n",
        "print('China: ', len(threshold(pr_China,thr)))\n",
        "print()\n",
        "print(threshold(pr_China,thr).iloc[:30])\n",
        "print()\n",
        "print('USA: ', len(threshold(pr_USA,thr)))\n",
        "print()\n",
        "print(threshold(pr_USA,thr).iloc[:30])\n",
        "print()\n",
        "print('China&USA: ', len(threshold(pr_China_USA,thr)))\n",
        "print()\n",
        "print(threshold(pr_China_USA,thr).iloc[:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqlZ2nZ9qKW"
      },
      "source": [
        "# TF-IDF: not performed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVbC8VFA9pgw"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,1))   # ngram range can be changed to obtain measures regarding n grams instead of single words\n",
        "\n",
        "X_China = tfidf.fit_transform(cleaned_text_China).toarray()    # entry (i,j) if Tfidf measure of word_list[j] in document i\n",
        "word_list_China = tfidf.get_feature_names_out()\n",
        "\n",
        "X_USA = tfidf.fit_transform(cleaned_text_USA).toarray()\n",
        "word_list_USA = tfidf.get_feature_names_out()\n",
        "\n",
        "X_China_USA = tfidf.fit_transform(cleaned_text_China_USA).toarray()\n",
        "word_list_China_USA = tfidf.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k8fcvKX-yah"
      },
      "outputs": [],
      "source": [
        "tfidf_df_China = pd.DataFrame(X_China,columns = word_list_China)\n",
        "\n",
        "tfidf_df_USA = pd.DataFrame(X_USA,columns = word_list_USA)\n",
        "\n",
        "tfidf_df_China_USA = pd.DataFrame(X_China_USA,columns = word_list_China_USA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUr9_93WCKsj"
      },
      "outputs": [],
      "source": [
        "tfidf_word_measure_China = np.mean(tfidf_df_China,axis = 0)\n",
        "tfidf_word_measure_China = tfidf_word_measure_China.sort_values(ascending = False)\n",
        "tfidf_word_measure_USA = np.mean(tfidf_df_USA,axis = 0)\n",
        "tfidf_word_measure_USA = tfidf_word_measure_USA.sort_values(ascending = False)\n",
        "tfidf_word_measure_China_USA = np.mean(tfidf_df_China_USA,axis = 0)\n",
        "tfidf_word_measure_China_USA = tfidf_word_measure_China_USA.sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(tfidf_word_measure_China[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(tfidf_word_measure_USA[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(tfidf_word_measure_China_USA[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dknv21f3XimF",
        "outputId": "be7d3fd2-d1cb-41ef-af97-37a9994ef55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "covid          0.076069\n",
            "watch          0.059429\n",
            "coronavirus    0.047427\n",
            "case           0.044577\n",
            "china          0.037314\n",
            "say            0.037011\n",
            "new            0.035957\n",
            "test           0.032966\n",
            "report         0.031964\n",
            "president      0.029373\n",
            "pandemic       0.029153\n",
            "vaccine        0.026741\n",
            "trump          0.026549\n",
            "update         0.026117\n",
            "health         0.025600\n",
            "country        0.024406\n",
            "positive       0.023640\n",
            "million        0.020711\n",
            "world          0.020349\n",
            "people         0.020237\n",
            "death          0.019359\n",
            "accord         0.017701\n",
            "late           0.017458\n",
            "sept           0.016890\n",
            "year           0.016416\n",
            "global         0.016072\n",
            "day            0.015739\n",
            "number         0.015450\n",
            "national       0.014457\n",
            "infection      0.014375\n",
            "dtype: float64\n",
            "\n",
            "USA:\n",
            "covid          0.063696\n",
            "coronavirus    0.043593\n",
            "case           0.032740\n",
            "say            0.031375\n",
            "new            0.030973\n",
            "vaccine        0.029819\n",
            "trump          0.026958\n",
            "test           0.026622\n",
            "president      0.021916\n",
            "report         0.021543\n",
            "positive       0.017711\n",
            "pandemic       0.016017\n",
            "death          0.015852\n",
            "day            0.013833\n",
            "house          0.012634\n",
            "infection      0.012417\n",
            "million        0.012382\n",
            "health         0.012242\n",
            "rise           0.012128\n",
            "state          0.011852\n",
            "trial          0.011631\n",
            "people         0.011513\n",
            "record         0.011287\n",
            "china          0.011244\n",
            "first          0.010940\n",
            "world          0.010269\n",
            "white          0.010210\n",
            "week           0.009885\n",
            "month          0.009750\n",
            "one            0.009536\n",
            "dtype: float64\n",
            "\n",
            "China&USA:\n",
            "covid          0.060835\n",
            "coronavirus    0.041928\n",
            "case           0.033042\n",
            "new            0.030410\n",
            "say            0.029997\n",
            "vaccine        0.027990\n",
            "test           0.025911\n",
            "trump          0.025467\n",
            "report         0.022188\n",
            "president      0.021459\n",
            "positive       0.017466\n",
            "pandemic       0.016267\n",
            "death          0.015868\n",
            "day            0.013524\n",
            "china          0.013455\n",
            "health         0.013341\n",
            "million        0.012933\n",
            "house          0.012178\n",
            "infection      0.012158\n",
            "people         0.011836\n",
            "state          0.011514\n",
            "rise           0.011490\n",
            "watch          0.011118\n",
            "record         0.010997\n",
            "world          0.010822\n",
            "country        0.010764\n",
            "trial          0.010702\n",
            "first          0.010654\n",
            "white          0.009986\n",
            "week           0.009475\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reduced graph"
      ],
      "metadata": {
        "id": "4nkLA8k0LB7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# less important words:\n",
        "less_important_words_China = list(threshold_reverse(pr_China,thr)[0])\n",
        "\n",
        "less_important_words_USA = list(threshold_reverse(pr_USA,thr)[0])\n",
        "\n",
        "less_important_words_China_USA = list(threshold_reverse(pr_China_USA,thr)[0])"
      ],
      "metadata": {
        "id": "6ndwCL9oLpDA"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_mostimp_text_China = clean_words(cleaned_text_China,less_important_words_China)\n",
        "cleaned_mostimp_text_USA = clean_words(cleaned_text_USA,less_important_words_USA)\n",
        "cleaned_mostimp_text_China_USA = clean_words(cleaned_text_China_USA,less_important_words_China_USA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOA3UEyBunzo",
        "outputId": "e9b204ea-5f8a-44a6-b8b0-9d13847d97e5"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 5018\n",
            "2000 / 5018\n",
            "4000 / 5018\n",
            "0 / 14548\n",
            "2000 / 14548\n",
            "4000 / 14548\n",
            "6000 / 14548\n",
            "8000 / 14548\n",
            "10000 / 14548\n",
            "12000 / 14548\n",
            "14000 / 14548\n",
            "0 / 19566\n",
            "2000 / 19566\n",
            "4000 / 19566\n",
            "6000 / 19566\n",
            "8000 / 19566\n",
            "10000 / 19566\n",
            "12000 / 19566\n",
            "14000 / 19566\n",
            "16000 / 19566\n",
            "18000 / 19566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict_China = frequency_dictionary(cleaned_mostimp_text_China)\n",
        "freq_dict_China = dict(sorted(freq_dict_China.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_USA = frequency_dictionary(cleaned_mostimp_text_USA)\n",
        "freq_dict_USA = dict(sorted(freq_dict_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "freq_dict_China_USA = frequency_dictionary(cleaned_mostimp_text_China_USA)\n",
        "freq_dict_China_USA = dict(sorted(freq_dict_China_USA.items(), key=lambda item: item[1], reverse = True))   #order from more frequent to less frequent word\n",
        "\n",
        "# number of words in the cleaned tweets:\n",
        "print('China: ', len(list(freq_dict_China)))\n",
        "print('USA: ', len(list(freq_dict_USA)))\n",
        "print('China&USA: ', len(list(freq_dict_China_USA)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3802822d-a14f-4b61-ba78-76e7b05dbe80",
        "id": "X2ObCNtJLpDB"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:  483\n",
            "USA:  522\n",
            "China&USA:  509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_China = pd.DataFrame.from_dict(freq_dict_China, orient='index').reset_index()\n",
        "df_China.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China.reset_index(inplace=True)\n",
        "df_China.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_USA = pd.DataFrame.from_dict(freq_dict_USA, orient='index').reset_index()\n",
        "df_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_USA.reset_index(inplace=True)\n",
        "df_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "df_China_USA = pd.DataFrame.from_dict(freq_dict_China_USA, orient='index').reset_index()\n",
        "df_China_USA.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "df_China_USA.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "df_China_USA.reset_index(inplace=True)\n",
        "df_China_USA.drop(columns=\"index\",inplace=True)\n",
        "\n",
        "print('China')\n",
        "print(df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA')\n",
        "print(df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA')\n",
        "print(df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bd4a6a-e2c2-4d31-e7bf-3168399d5670",
        "id": "DfrViAqzNnb9"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China\n",
            "           Word  Count\n",
            "0         china   1613\n",
            "1         covid   1593\n",
            "2          case    933\n",
            "3       vaccine    906\n",
            "4   coronavirus    852\n",
            "5         novel    847\n",
            "6           new    670\n",
            "7           say    632\n",
            "8        report    502\n",
            "9      outbreak    495\n",
            "10     hospital    474\n",
            "11       health    448\n",
            "12       people    419\n",
            "13      country    384\n",
            "14      patient    366\n",
            "15        fight    357\n",
            "16      confirm    336\n",
            "17        first    323\n",
            "18        death    298\n",
            "19    president    286\n",
            "20      million    275\n",
            "21          day    267\n",
            "22        world    257\n",
            "23         test    248\n",
            "24     pandemic    241\n",
            "25         city    222\n",
            "26         year    219\n",
            "27    infection    216\n",
            "28         amid    216\n",
            "29          one    215\n",
            "\n",
            "USA\n",
            "           Word  Count\n",
            "0         covid   7147\n",
            "1   coronavirus   5048\n",
            "2       vaccine   3282\n",
            "3           say   2741\n",
            "4          case   1943\n",
            "5           new   1889\n",
            "6         china   1694\n",
            "7         trump   1319\n",
            "8          test   1254\n",
            "9     president   1150\n",
            "10       report    973\n",
            "11        death    916\n",
            "12       people    913\n",
            "13       health    901\n",
            "14     outbreak    841\n",
            "15     pandemic    801\n",
            "16        first    780\n",
            "17        state    700\n",
            "18     positive    678\n",
            "19      country    675\n",
            "20      million    653\n",
            "21          day    649\n",
            "22        world    637\n",
            "23       spread    635\n",
            "24    infection    549\n",
            "25         rise    547\n",
            "26        virus    543\n",
            "27        house    532\n",
            "28      johnson    524\n",
            "29          get    521\n",
            "\n",
            "China&USA\n",
            "           Word  Count\n",
            "0         covid   8740\n",
            "1   coronavirus   5900\n",
            "2       vaccine   4188\n",
            "3           say   3373\n",
            "4         china   3307\n",
            "5          case   2876\n",
            "6           new   2559\n",
            "7          test   1502\n",
            "8        report   1475\n",
            "9         trump   1449\n",
            "10    president   1436\n",
            "11       health   1349\n",
            "12     outbreak   1336\n",
            "13       people   1332\n",
            "14        death   1214\n",
            "15        first   1103\n",
            "16      country   1059\n",
            "17     pandemic   1042\n",
            "18        novel    979\n",
            "19      million    928\n",
            "20          day    916\n",
            "21        world    894\n",
            "22     hospital    855\n",
            "23        state    844\n",
            "24     positive    819\n",
            "25    infection    765\n",
            "26       spread    765\n",
            "27        virus    719\n",
            "28         year    697\n",
            "29          one    679\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_China = freq_dict_China.keys()  \n",
        "keys_USA = freq_dict_USA.keys()  \n",
        "keys_China_USA = freq_dict_China_USA.keys()  "
      ],
      "metadata": {
        "id": "Q52SCkkKNncF"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_China, network_df_China = create_network(cleaned_mostimp_text_China)\n",
        "network_USA, network_df_USA = create_network(cleaned_mostimp_text_USA)\n",
        "network_China_USA, network_df_China_USA = create_network(cleaned_mostimp_text_China_USA)"
      ],
      "metadata": {
        "id": "bPn3tfv7NncF"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print(network_df_China.iloc[0:30])\n",
        "print()\n",
        "print('USA:')\n",
        "print(network_df_USA.iloc[0:30])\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(network_df_China_USA.iloc[0:30])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7f590e-0f1c-4a4a-edcd-26f775e867cf",
        "id": "MVggBElVNncF"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "                      weight\n",
            "(vaccine, covid)         571\n",
            "(new, case)              501\n",
            "(china, novel)           497\n",
            "(report, case)           434\n",
            "(china, covid)           404\n",
            "(confirm, case)          397\n",
            "(china, coronavirus)     319\n",
            "(case, covid)            306\n",
            "(report, new)            304\n",
            "(china, outbreak)        300\n",
            "(china, vaccine)         293\n",
            "(novel, coronavirus)     291\n",
            "(patient, hospital)      275\n",
            "(china, case)            273\n",
            "(say, china)             257\n",
            "(death, case)            257\n",
            "(china, fight)           254\n",
            "(covid, say)             236\n",
            "(new, covid)             233\n",
            "(novel, outbreak)        226\n",
            "(china, new)             206\n",
            "(report, covid)          204\n",
            "(million, covid)         197\n",
            "(case, coronavirus)      193\n",
            "(case, number)           189\n",
            "(covid, pandemic)        189\n",
            "(covid, country)         186\n",
            "(case, total)            180\n",
            "(vaccine, receive)       175\n",
            "(health, covid)          174\n",
            "\n",
            "USA:\n",
            "                         weight\n",
            "(vaccine, covid)           2180\n",
            "(say, covid)               1456\n",
            "(china, coronavirus)       1221\n",
            "(president, trump)         1031\n",
            "(covid, case)              1025\n",
            "(new, covid)               1023\n",
            "(vaccine, say)              892\n",
            "(say, coronavirus)          872\n",
            "(coronavirus, case)         869\n",
            "(test, covid)               785\n",
            "(new, coronavirus)          732\n",
            "(new, case)                 719\n",
            "(trump, covid)              705\n",
            "(test, positive)            685\n",
            "(coronavirus, outbreak)     648\n",
            "(president, covid)          593\n",
            "(trump, say)                561\n",
            "(report, covid)             534\n",
            "(report, case)              502\n",
            "(trump, coronavirus)        490\n",
            "(say, president)            489\n",
            "(test, coronavirus)         481\n",
            "(coronavirus, death)        478\n",
            "(white, house)              472\n",
            "(spread, coronavirus)       466\n",
            "(covid, death)              431\n",
            "(vaccine, trial)            428\n",
            "(report, new)               424\n",
            "(say, test)                 422\n",
            "(positive, covid)           418\n",
            "\n",
            "China&USA:\n",
            "                         weight\n",
            "(vaccine, covid)           2751\n",
            "(covid, say)               1692\n",
            "(china, coronavirus)       1540\n",
            "(case, covid)              1331\n",
            "(new, covid)               1256\n",
            "(new, case)                1220\n",
            "(president, trump)         1135\n",
            "(case, coronavirus)        1062\n",
            "(vaccine, say)             1054\n",
            "(say, coronavirus)          958\n",
            "(report, case)              936\n",
            "(test, covid)               902\n",
            "(coronavirus, new)          891\n",
            "(test, positive)            824\n",
            "(coronavirus, outbreak)     779\n",
            "(trump, covid)              772\n",
            "(report, covid)             738\n",
            "(report, new)               728\n",
            "(president, covid)          723\n",
            "(china, covid)              670\n",
            "(china, outbreak)           659\n",
            "(confirm, case)             644\n",
            "(china, case)               607\n",
            "(trump, say)                606\n",
            "(health, covid)             578\n",
            "(president, say)            570\n",
            "(covid, pandemic)           568\n",
            "(covid, country)            547\n",
            "(million, covid)            546\n",
            "(first, covid)              542\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_China = get_graph(network_China)\n",
        "G_USA = get_graph(network_USA)\n",
        "G_China_USA = get_graph(network_China_USA)"
      ],
      "metadata": {
        "id": "zNrH5boVNncF"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('China:')\n",
        "print('Nodes: ',len(G_China.nodes()))\n",
        "print('Edges: ',len(G_China.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China))\n",
        "print()\n",
        "print('USA:')\n",
        "print('Nodes: ',len(G_USA.nodes()))\n",
        "print('Edges: ',len(G_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_USA))\n",
        "print()\n",
        "print('China&USA:')\n",
        "print('Nodes: ',len(G_China_USA.nodes()))\n",
        "print('Edges: ',len(G_China_USA.edges()))\n",
        "print('Is connected: ',nx.is_connected(G_China_USA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce01533d-d051-40f2-aa39-e138c3c95845",
        "id": "kx5041hFNncF"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "Nodes:  483\n",
            "Edges:  42457\n",
            "Is connected:  True\n",
            "\n",
            "USA:\n",
            "Nodes:  522\n",
            "Edges:  70403\n",
            "Is connected:  True\n",
            "\n",
            "China&USA:\n",
            "Nodes:  509\n",
            "Edges:  78747\n",
            "Is connected:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save edge list"
      ],
      "metadata": {
        "id": "p4SvWlzSfzFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = './edgelist_China'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_China, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China.csv\n",
        "files.download('edgelist_China'+period+'.csv')\n",
        "\n",
        "filename = './edgelist_USA'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_USA.csv\n",
        "files.download('edgelist_USA'+period+'.csv')\n",
        "\n",
        "filename = './edgelist_China_USA'+period+'.csv'\n",
        "nx.write_weighted_edgelist(G_China_USA, filename, delimiter=\",\")\n",
        "#add header with appropriate column names (works on colab and Linux/Mac(?))\n",
        "!sed -i.bak 1i\"Source,Target,Weight\" ./edgelist_China_USA.csv\n",
        "files.download('edgelist_China_USA'+period+'.csv')"
      ],
      "metadata": {
        "id": "zgmmRGRCrM9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "01498827-2e80-4cab-815a-c248969110e4"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_998a690c-24e7-4df1-9fed-f1c180e1f230\", \"edgelist_China.csv\", 665039)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e8c47151-e5ee-42ce-b763-630f0c32b7d3\", \"edgelist_USA.csv\", 1087441)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_484361cc-0755-4080-9043-c33228f3a797\", \"edgelist_China_USA.csv\", 1225065)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create Node List\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nWHLO7AhdwzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes(freq_dict, name):\n",
        "  word_nodes = pd.DataFrame.from_dict(freq_dict,orient=\"index\")\n",
        "  word_nodes.reset_index(inplace=True)\n",
        "  word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
        "  word_nodes.rename(columns={\"index\":\"Id\",0:\"delete\"},inplace=True)\n",
        "  word_nodes = word_nodes.drop(columns=['delete'])\n",
        "  nodelist = pd.DataFrame()\n",
        "  nodelist = nodelist.append(word_nodes, ignore_index=True)\n",
        "\n",
        "  nodelist = nodelist.to_csv(\"nodelist_\"+name+\".csv\",index=False)\n",
        "  files.download(\"nodelist_\"+name+\".csv\")\n",
        "  return nodelist, word_nodes"
      ],
      "metadata": {
        "id": "v2GYb2BQFzET"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodelist_China, word_nodes_China = nodes(freq_dict_China,'China'+period)\n",
        "nodelist_USA, word_nodes_USA = nodes(freq_dict_USA,'USA_'+period)\n",
        "nodelist_China_USA, word_nodes_China_USA = nodes(freq_dict_China_USA,'China_USA'+period)\n",
        "\n",
        "print('China:')\n",
        "print(word_nodes_China.head())\n",
        "print()\n",
        "print('USA:')\n",
        "print(word_nodes_USA.head())\n",
        "print()\n",
        "print('China&USA:')\n",
        "print(word_nodes_China_USA.head())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EmQrEHV0F1QY",
        "outputId": "329becd7-c299-4270-8714-626c101963b3"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e426e01b-e3d5-4e3c-a03d-4e406b38cd85\", \"nodelist_China.csv\", 6595)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5702825c-7b60-44a4-abe6-1d0053036066\", \"nodelist_USA_.csv\", 7077)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_82e47450-9c12-40f7-8441-f2de1bde5cc5\", \"nodelist_China_USA.csv\", 6907)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China:\n",
            "            Id        Label\n",
            "0        china        china\n",
            "1        covid        covid\n",
            "2         case         case\n",
            "3      vaccine      vaccine\n",
            "4  coronavirus  coronavirus\n",
            "\n",
            "USA:\n",
            "            Id        Label\n",
            "0        covid        covid\n",
            "1  coronavirus  coronavirus\n",
            "2      vaccine      vaccine\n",
            "3          say          say\n",
            "4         case         case\n",
            "\n",
            "China&USA:\n",
            "            Id        Label\n",
            "0        covid        covid\n",
            "1  coronavirus  coronavirus\n",
            "2      vaccine      vaccine\n",
            "3          say          say\n",
            "4        china        china\n",
            "\n"
          ]
        }
      ]
    }
  ]
}